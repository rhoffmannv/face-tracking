{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as alb\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recolectar imágenes con OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir el número de imágenes a generar inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_IMAGENES = os.path.join('data','imagenes')\n",
    "n_imagenes = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear carpeta para guardar imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(PATH_IMAGENES)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Abrir videocamara con OpenCV.\n",
    "- Capturar *n_imagenes* imágenes, una cada medio segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for imgnum in range(n_imagenes):\n",
    "    print('Imagen {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(PATH_IMAGENES,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear anotaciones con LabelMe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear carpeta para guardar anotaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(os.path.join(\"data\", \"labels\"))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir programa LabelMe para crear manualmente las anotaciones.\n",
    "\n",
    "- Permite hacer rectángulo (*box*) fácilmente sobre imagen y colocarle *label* (etiqueta).\n",
    "- Guarda *json* por cada imagen con las coordenadas del rectángulo y el *label*.\n",
    "\n",
    "> Si no está instalado, ejecutar comando *pip install labelme*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar en conjuntos de entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear carpetas para imagenes y anotaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for carpeta in ['train','test','val']:\n",
    "    try: \n",
    "        os.makedirs(os.path.join(\"data\", carpeta))\n",
    "        os.makedirs(os.path.join(\"data\", carpeta, \"imagenes\"))\n",
    "        os.makedirs(os.path.join(\"data\", carpeta, \"labels\"))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar imagenes en conjuntos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje_val = 0.15\n",
    "porcentaje_test = 0.15\n",
    "imagenes = np.array(os.listdir(PATH_IMAGENES))\n",
    "\n",
    "shuffled_indices = np.random.permutation(len(imagenes))\n",
    "\n",
    "n_val = int(len(imagenes) * porcentaje_val)\n",
    "n_test = int(len(imagenes) * porcentaje_test)\n",
    "indices_val = shuffled_indices[: n_val]\n",
    "indices_test = shuffled_indices[n_val : n_test + n_val]\n",
    "indices_train = shuffled_indices[n_test + n_val :]\n",
    "\n",
    "imagenes_train = imagenes[indices_train]\n",
    "imagenes_val = imagenes[indices_val]\n",
    "imagenes_test = imagenes[indices_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mover las imágenes a las carpetas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagen in imagenes_train:\n",
    "    path_inicial = os.path.join(PATH_IMAGENES, imagen)\n",
    "    path_final = os.path.join(\"data\", \"train\", \"imagenes\", imagen)\n",
    "    os.replace(path_inicial, path_final)\n",
    "    \n",
    "for imagen in imagenes_val:\n",
    "    path_inicial = os.path.join(PATH_IMAGENES, imagen)\n",
    "    path_final = os.path.join(\"data\", \"val\", \"imagenes\", imagen)\n",
    "    os.replace(path_inicial, path_final)\n",
    "    \n",
    "for imagen in imagenes_test:\n",
    "    path_inicial = os.path.join(PATH_IMAGENES, imagen)\n",
    "    path_final = os.path.join(\"data\", \"test\", \"imagenes\", imagen)\n",
    "    os.replace(path_inicial, path_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mover las anotaciones correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for carpeta in ['train','test','val']:\n",
    "    for imagen in os.listdir(os.path.join('data', carpeta, 'imagenes')):\n",
    "        \n",
    "        nombre = imagen.split('.')[0]+'.json'\n",
    "        path_label = os.path.join('data','labels', nombre)\n",
    "        if os.path.exists(path_label): \n",
    "            nuevo_path_label = os.path.join('data', carpeta ,'labels', nombre)\n",
    "            os.replace(path_label, nuevo_path_label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aumento de datos (Data augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear carpetas para las imágenes y las etiquetas \"aumentadas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for carpeta in ['train','test','val']:\n",
    "    try: \n",
    "        os.makedirs(os.path.join(\"aug_data\", carpeta))\n",
    "        os.makedirs(os.path.join(\"aug_data\", carpeta, \"imagenes\"))\n",
    "        os.makedirs(os.path.join(\"aug_data\", carpeta, \"labels\"))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea objeto \"augmentor\" con parametros a usar para cambiar imagen original.\n",
    "- Se pasan también las coordenadas del rectángulo y las labels para que las modifique acorde a la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se aplica la transformación definida en *augmentor* *n_multiplicacion* veces sobre cada imagen.\n",
    "- Se obtienen *n_multiplicacion* nuevos *datapoint* por cada *datapoint* original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_multiplicacion = 60\n",
    "for carpeta in ['train','test','val']: \n",
    "    for imagen in os.listdir(os.path.join('data', carpeta, 'imagenes')):\n",
    "        img = cv2.imread(os.path.join('data', carpeta, 'imagenes', imagen))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', carpeta, 'labels', f'{imagen.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [640,480,640,480]))\n",
    "\n",
    "        try: \n",
    "            for x in range(n_multiplicacion):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', carpeta, 'imagenes', f'{imagen.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                anotacion = {}\n",
    "                anotacion['image'] = imagen\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        anotacion['bbox'] = [0,0,0,0]\n",
    "                        anotacion['class'] = 0 \n",
    "                    else: \n",
    "                        anotacion['bbox'] = augmented['bboxes'][0]\n",
    "                        anotacion['class'] = 1\n",
    "                else: \n",
    "                    anotacion['bbox'] = [0,0,0,0]\n",
    "                    anotacion['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', carpeta, 'labels', f'{imagen.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(anotacion, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de imágenes\n",
    "\n",
    "- Se cargan las imágenes desde su *path* a un tensor de TensorFlow.\n",
    "- Se escalan a *120 x 120* pixeles.\n",
    "- Se escalan los valores de cada pixel entre 0 y 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imagenes = tf.data.Dataset.list_files('aug_data\\\\train\\\\imagenes\\\\*.jpg', shuffle=False)\n",
    "train_imagenes = train_imagenes.map(load_image)\n",
    "train_imagenes = train_imagenes.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "train_imagenes = train_imagenes.map(lambda x: x/255)\n",
    "\n",
    "val_imagenes = tf.data.Dataset.list_files('aug_data\\\\val\\\\imagenes\\\\*.jpg', shuffle=False)\n",
    "val_imagenes = val_imagenes.map(load_image)\n",
    "val_imagenes = val_imagenes.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "val_imagenes = val_imagenes.map(lambda x: x/255)\n",
    "\n",
    "test_imagenes = tf.data.Dataset.list_files('aug_data\\\\test\\\\imagenes\\\\*.jpg', shuffle=False)\n",
    "test_imagenes = test_imagenes.map(load_image)\n",
    "test_imagenes = test_imagenes.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "test_imagenes = test_imagenes.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de etiquetas\n",
    "\n",
    "- Se cargan los archivos de anotaciones formato *json*.\n",
    "- Se extraen la etiqueta y las coordenadas de los rectángulos y se crea en tensor a partir de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n",
    "\n",
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n",
    "\n",
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir dataset\n",
    "\n",
    "Se unen los tensores correspondientes a las imágenes con los tensores de las etiquetas, por cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_imagenes, train_labels))\n",
    "train = train.shuffle(5000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)\n",
    "\n",
    "val = tf.data.Dataset.zip((val_imagenes, val_labels))\n",
    "val = val.shuffle(1000)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)\n",
    "\n",
    "test = tf.data.Dataset.zip((test_imagenes, test_labels))\n",
    "test = test.shuffle(1300)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de VGG16\n",
    "\n",
    "Se descarga la red neuronal convolucional VGG16 ya preentrenada, sin las capas finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir el modelo\n",
    "\n",
    "El modelo consiste en dos partes:\n",
    "   - Clasificación: Para determinar la etiqueta de la detección.\n",
    "   - Regresión: Para predecir las coordenadas del rectángulo donde se encuentra el objeto.\n",
    "   \n",
    "Cada parte se basa en las *feature* entregadas por la red VGG16 y agrega capas sobre esta.\n",
    "   - Clasificación: Agrega una capa de *Max Pooling*, luego una capa oculta *fully connected* y finalmente la capa de salida con una neurona y activación sigmoidea.\n",
    "   - Regresión: Agrega una capa de *Max Pooling*, luego una capa oculta *fully connected* y finalmente la capa de salida con 4 neuronas de salida y función de activación sigmoidea.\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    capa_entrada = Input(shape=(120,120,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(capa_entrada)\n",
    "\n",
    "    # Modelo para clasificación\n",
    "    capa_pooling_clasificador = GlobalMaxPooling2D()(vgg)\n",
    "    capa_oculta_clasificador = Dense(2048, activation='relu')(capa_pooling_clasificador)\n",
    "    salida_clasificador = Dense(1, activation='sigmoid')(capa_oculta_clasificador)\n",
    "    \n",
    "    # Modelo para predicción de coordenadas del rectángulo\n",
    "    capa_pooling_regresor = GlobalMaxPooling2D()(vgg)\n",
    "    capa_oculta_regresor = Dense(2048, activation='relu')(capa_pooling_regresor)\n",
    "    salida_regresor = Dense(4, activation='sigmoid')(capa_oculta_regresor)\n",
    "    \n",
    "    modelo = Model(inputs=capa_entrada, outputs=[salida_clasificador, salida_regresor])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir optimizador y paramétros de entrenamiento\n",
    "\n",
    "Se usa Adam como optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batches_por_epoca = len(train)\n",
    "lr_decay = (1./0.75 -1)/batches_por_epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizador = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir función de loss para regresión\n",
    "\n",
    "Se usa la función de pérdida:\n",
    "\n",
    "$$loss = \\sum (x - \\hat{x})^2 + (y - \\hat{y})^2 + (w - \\hat{w})^2 + (h - \\hat{h})^2$$\n",
    "\n",
    "- Donde *x* corresponde a la primera coordenada del punto superior izquierdo del rectángulo.\n",
    "- Donde *y* corresponde a la segunda coordenada del punto superior izquierdo del rectángulo.\n",
    "- Donde *w* corresponde al ancho del rectángulo.\n",
    "- Donde *h* corresponde al alto del rectángulo.\n",
    "\n",
    "- El \"sombrero\" hace referencia a la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_regresion(y_true, yhat):            \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] \n",
    "    w_true = y_true[:,2] - y_true[:,0] \n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir loss para clasificación\n",
    "Se usa Entropía cruzada para la pérdida de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_clasificacion = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear clase Modelo personalizada\n",
    "\n",
    "Requiere definir los siguientes métodos:\n",
    "\n",
    "- **compile**: Para declarar las funciones de *loss* y el optimizador a utilizar para entrenar.\n",
    "- **train_step**: Para ajustar los pesos del modelo usando gradiente descendiente. Notar que se usa como función de *loss* una suma ponderada del *loss* de regresión y el de clasificación.\n",
    "- **test_step**: Para realizar una predicciones sobre el conjunto de *test*. Guarda las *losses* en un diccionario.\n",
    "- **call**: Para hacer predicciones con el modelo, se llama con el método *predict*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FaceTracker(Model): \n",
    "    def __init__(self, eyetracker,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = eyetracker\n",
    "\n",
    "    def compile(self, optimizador, loss_clasificacion, loss_regresion, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.loss_clasificacion = loss_clasificacion\n",
    "        self.loss_regresion = loss_regresion\n",
    "        self.opt = optimizador\n",
    "    \n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            clases, coords = self.model(X, training=True)\n",
    "            \n",
    "            loss_clasificacion_batch = self.loss_clasificacion(y[0], clases)\n",
    "            loss_regresion_batch = self.loss_regresion(tf.cast(y[1], tf.float32), coords)\n",
    "            \n",
    "            loss_total = loss_regresion_batch+0.5*loss_clasificacion_batch\n",
    "            \n",
    "            grad = tape.gradient(loss_total, self.model.trainable_variables)\n",
    "        \n",
    "        self.opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"loss_total\":loss_total, \"loss_clasificacion\":loss_clasificacion_batch, \"loss_regresion\":loss_regresion_batch}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        clases, coords = self.model(X, training=False)\n",
    "        \n",
    "        loss_clasificacion_batch = self.closs(y[0], clases)\n",
    "        loss_regresion_batch = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        loss_total = loss_regresion_batch +0.5*loss_clasificacion_batch\n",
    "        \n",
    "        {\"loss_total\":loss_total, \"loss_clasificacion\":loss_clasificacion_batch, \"loss_regresion\":loss_regresion_batch}\n",
    "    \n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo = FaceTracker(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo.compile(optimizador, loss_clasificacion, loss_regresion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU\n",
    "Verificar si se tiene GPU para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de GPUs disponibles: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitar crecimiento de uso de memoría por GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el modelo\n",
    "\n",
    "- Se define el directorio para el *callback* de Tensorboard (Permite ver los resultados del entrenamiento en tiempo real).\n",
    "- Se ejecuta el método *fit* para ajustar los pesos con los datos de entrenamiento.\n",
    "- Se ingresa el conjunto de validación para ir calculando el *loss* tanto en entrenamiento como en validación para poder evaluar si existe *overfitting* o *underfittting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback_tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = modelo.fit(train, epochs=10, validation_data=val, callbacks=[callback_tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar losses en entrenamiento y en validación\n",
    "\n",
    "- Se hacen 3 gráficos de *losses*: *loss* total, *loss* de clasificación y *loss* de regresión.\n",
    "- Por cada uno se grafican tanto el *loss* de entrenamiento como el *loss* de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
    "\n",
    "ax[0].plot(hist.history['loss_total'], color='teal', label='train loss')\n",
    "ax[0].plot(hist.history['val_loss_total'], color='orange', label='val loss')\n",
    "ax[0].title.set_text('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(hist.history['loss_clasificacion'], color='teal', label='train loss')\n",
    "ax[1].plot(hist.history['val_loss_clasificacion'], color='orange', label='val loss')\n",
    "ax[1].title.set_text('Loss de clasificación')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(hist.history['loss_regresion'], color='teal', label='train loss')\n",
    "ax[2].plot(hist.history['val_loss_regresion'], color='orange', label='val loss')\n",
    "ax[2].title.set_text('Loss de regresión')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save('modelo.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "modelo = load_model('modelo.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predicciones en el conjunto de prueba\n",
    "\n",
    "Se carga un batch de conjunto de prueba y se hace predicción con el modelo obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()\n",
    "ejemplo_test = test_data.next()\n",
    "prediccion = modelo.predict(ejemplo_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se grafican 4 imágenes del batch de prueba y se dibuja encima el rectángulo predicho por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    ejemplo_imagen = ejemplo_test[0][idx]\n",
    "    ejemplo_coords = prediccion[1][idx]\n",
    "    \n",
    "    if prediccion[0][idx] > 0.9:\n",
    "        cv2.rectangle(ejemplo_imagen, \n",
    "                      tuple(np.multiply(ejemplo_coords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(ejemplo_coords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(ejemplo_imagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementar el modelo\n",
    "\n",
    "- Se abre videocamera con OpenCV.\n",
    "- Se toman los *frame* y se recortan, tomando los primeros *450 x 450* pixeles.\n",
    "- Se reescala y normaliza el *frame* para poder ingresarlo al modelo.\n",
    "- Se realiza predicción con el modelo.\n",
    "- Se dibuja rectangulo con cv2.rectangle y label con cv2.putText.\n",
    "- Se muestra el *frame* modificado en pantalla.\n",
    "- Salir presionando \"q\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    \n",
    "    tamano_frame = [450, 450]\n",
    "    print(frame.shape)\n",
    "    frame = frame[0:450, 0:450,:]\n",
    "    \n",
    "    print(frame.shape)\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_escalada = tf.image.resize(rgb, (120,120))\n",
    "    \n",
    "    prediccion = modelo.predict(np.expand_dims(img_escalada/255,0))\n",
    "    coords = prediccion[1][0]\n",
    "    \n",
    "    if prediccion[0] > 0.5: \n",
    "        # Recuadro de prediccion\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(coords[:2], tamano_frame).astype(int)),\n",
    "                      tuple(np.multiply(coords[2:], tamano_frame).astype(int)),\n",
    "                            (255,0,0), 2)\n",
    "        # Recuadro para label\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(coords[:2], tamano_frame).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(coords[:2], tamano_frame).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        \n",
    "        # Texto con label de clasificación\n",
    "        cv2.putText(frame, 'face', tuple(np.add(np.multiply(coords[:2], tamano_frame).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('FaceTracker', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
